{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oy7XcpiERrx"
      },
      "source": [
        "# DL톤 해파리 분류기\n",
        "아이펠 코어 12기 팀: 해파리지앵  \n",
        "@author: Hyeseung Lee  \n",
        "Created: 2025-04-01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FqmRzhHElX4"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "해파리 분류기 노트북 코드 요약 설명\n",
        "이 노트북 코드는 딥러닝을 사용하여 해파리 이미지를 분류하는 모델을 구축하고 훈련하는 과정을 담고 있습니다. 주요 기능과 단계는 다음과 같습니다.\n",
        "\n",
        "1. 데이터 준비 및 전처리:\n",
        "\n",
        "Google Drive에 저장된 해파리 이미지 데이터셋을 불러옵니다. 데이터셋은 훈련, 검증, 테스트셋으로 나뉘어져 있습니다.\n",
        "load_dataset_from_directory 함수를 사용하여 이미지를 로드하고 크기를 조정합니다.\n",
        "count_images_per_class 함수를 사용하여 각 클래스별 이미지 개수를 확인하고 데이터 분포를 파악합니다.\n",
        "get_class_labels 함수를 사용하여 디렉토리 구조를 기반으로 클래스 레이블을 자동으로 추출합니다.\n",
        "2. 데이터 증강:\n",
        "\n",
        "AugmentationManager 클래스를 사용하여 훈련 이미지에 대한 데이터 증강 파이프라인을 생성합니다.\n",
        "회전, 이동, 확대/축소, 수평 뒤집기 등 다양한 증강 기법을 적용하여 모델의 일반화 성능을 향상시킵니다.\n",
        "apply_augmentation 함수를 사용하여 증강된 이미지를 생성하고 시각화하여 증강 결과를 확인합니다.\n",
        "gaussian_blur, salt_and_pepper_noise, gaussian_noise 함수를 통해 추가적인 노이즈 증강 기법을 적용할 수 있습니다.\n",
        "3. 모델 구축 및 훈련:\n",
        "\n",
        "JellyfishClassifier 클래스를 사용하여 해파리 분류 모델을 정의합니다.\n",
        "EfficientNet, MobileNet, ResNet 등 다양한 사전 훈련된 모델을 기반으로 모델을 구축할 수 있습니다.\n",
        "fit 메서드를 사용하여 모델을 훈련합니다. 훈련 과정에서 검증 데이터를 사용하여 모델 성능을 평가하고 조기 종료 및 체크포인트 기능을 활용하여 최적의 모델을 저장합니다.\n",
        "훈련 중에는 TqdmCallback을 사용하여 진행 상황을 시각적으로 표시합니다.\n",
        "ReduceLROnPlateau 콜백을 사용하여 검증 손실이 정체될 경우 학습률을 조정합니다.\n",
        "4. 모델 평가 및 시각화:\n",
        "\n",
        "evaluate 메서드를 사용하여 테스트 데이터셋에 대한 모델 성능을 평가합니다. 정확도, F1 점수, 엔트로피 등 다양한 지표를 사용하여 모델 성능을 측정합니다.\n",
        "Test Time Augmentation (TTA) 기법을 적용하여 모델 예측의 정확도를 높일 수 있습니다.\n",
        "k_fold_cross_validation 메서드를 사용하여 K-fold 교차 검증을 수행하고 모델의 일반화 성능을 평가합니다.\n",
        "plot_confusion_matrix 함수를 사용하여 혼동 행렬을 시각화하고 모델의 예측 오류를 분석합니다.\n",
        "plot_training_history 함수를 사용하여 훈련 과정에서의 손실 및 정확도 변화를 시각화합니다.\n",
        "5. 모델 저장 및 로드:\n",
        "\n",
        "save_model 메서드를 사용하여 훈련된 모델을 파일로 저장합니다.\n",
        "load_model 메서드를 사용하여 저장된 모델을 불러와서 사용할 수 있습니다.\n",
        "6. 예측:\n",
        "\n",
        "predict 메서드를 사용하여 새로운 이미지에 대한 예측을 수행합니다.\n",
        "TTA 기법을 적용하여 예측 정확도를 높일 수 있습니다.\n",
        "요약:\n",
        "\n",
        "이 노트북 코드는 데이터 준비, 증강, 모델 구축, 훈련, 평가, 시각화, 저장, 로드, 예측 등 딥러닝 모델 개발의 전 과정을 포함하고 있습니다. 다양한 기능과 옵션을 제공하여 사용자가 해파리 이미지 분류 모델을 효과적으로 구축하고 실험할 수 있도록 지원합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyxDZBJ7O4yG"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7dBkpoWE273"
      },
      "source": [
        "### 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ri5sZG_E_h42",
        "outputId": "28b680f0-ae9e-4bce-9f4a-caec897f2ca0"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "v5iNUD8FU1rM",
        "outputId": "6c003eef-11e7-488a-885b-34eb6ee4eee6"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "j1ToDVAGjV2x",
        "outputId": "ad210493-5660-4540-b5dd-18398a3c8e60"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WALCcqsPkwvg",
        "outputId": "55a17141-72b9-46ef-c352-4e196ff7387f"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-image --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Chc1dMuimGM4",
        "outputId": "69e6d81c-2a7e-4052-9c6c-c1914bca452c"
      },
      "outputs": [],
      "source": [
        "!pip install albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX5V4Mne3dS2"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from tqdm.keras import TqdmCallback\n",
        "from tqdm.auto import tqdm  # Import tqdm.auto\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "from scipy.stats import mode\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "import math\n",
        "import random\n",
        "import glob\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models, callbacks, applications\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import KFold\n",
        "import cv2\n",
        "import albumentations as A  # Import Albumentations\n",
        "from albumentations.core.composition import OneOf\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkkCcykmTSoY"
      },
      "source": [
        "### 함수 모듈화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtJz1OTiwdyH"
      },
      "outputs": [],
      "source": [
        "def load_dataset_from_directory(directory, img_size=(224, 224), batch_size=32, flatten=False):\n",
        "    \"\"\"폴더에서 RGB 이미지 데이터셋을 로드하는 함수 (최신 TensorFlow 방식)\"\"\"\n",
        "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        directory,\n",
        "        image_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        color_mode='rgb',\n",
        "        shuffle=True,\n",
        "        seed=42,\n",
        "        labels='inferred',\n",
        "        label_mode='int'\n",
        "    )\n",
        "\n",
        "    # 클래스 이름 가져오기\n",
        "    class_names = dataset.class_names\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    # 데이터셋 전처리 (정규화)\n",
        "    def preprocess(images, labels):\n",
        "        images = tf.cast(images, tf.float32) / 255.0\n",
        "        return images, labels\n",
        "\n",
        "    dataset = dataset.map(preprocess)\n",
        "\n",
        "    # 전체 데이터 메모리에 로드\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "\n",
        "    for images, labels in dataset:\n",
        "        X_list.append(images.numpy())\n",
        "        y_list.append(labels.numpy())\n",
        "\n",
        "    X = np.concatenate(X_list, axis=0)\n",
        "    y = np.concatenate(y_list, axis=0)\n",
        "\n",
        "    # 필요한 경우 평탄화(flatten)\n",
        "    if flatten:\n",
        "        X = X.reshape(X.shape[0], -1)  # (n_samples, height*width*channels)\n",
        "\n",
        "    # 그레이스케일 특화 코드\n",
        "    # 기존: elif color_mode == 'grayscale': X = X[..., 0]\n",
        "\n",
        "    return X, y, class_dict\n",
        "\n",
        "def get_class_labels(data_path):\n",
        "  \"\"\"\n",
        "  디렉토리 구조를 기반으로 클래스 레이블 추론\n",
        "\n",
        "  Args:\n",
        "    data_path: 클래스 별 하위폴더를 포함하는 데이터셋의 상위 디렉토리\n",
        "\n",
        "  Returns:\n",
        "    클래스 레이블을 딕셔너리로 반환\n",
        "  \"\"\"\n",
        "  class_labels = {}\n",
        "  for folder_name in os.listdir(data_path):\n",
        "    folder_path = os.path.join(data_path, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "      class_labels[folder_name] = folder_name  # Assuming directory name is the class label\n",
        "  return class_labels\n",
        "\n",
        "# Define your augmentation function\n",
        "def augment(image, label,\n",
        "            crop_ratio=1.0,\n",
        "            saturation = (0.8, 1.2),\n",
        "            brightness_max_delta=0.1,\n",
        "            random_contrast=(0.9,1.1),\n",
        "            random_hue = 0.1,\n",
        "            random_flip_left_right = True,\n",
        "            random_flip_up_down = True,\n",
        "            random_rotation = 180, #TODO: THIS IS NOT WORKING AS IT IS NOT RANDOM BUT FIXED 90 DEGREES\n",
        "            gaussian_noise_mean=0.0,\n",
        "            gaussian_noise_stddev=0.05\n",
        "            ):\n",
        "    img_shape = np.array(list(image.shape))\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.rot90(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=brightness_max_delta)\n",
        "    image = tf.image.random_contrast(image, random_contrast[0],random_contrast[1])\n",
        "    image = tf.image.random_saturation(image, saturation[0], saturation[1])\n",
        "    image = tf.image.random_hue(image, random_hue)\n",
        "    image = tf.image.random_crop(image, size=np.hstack([img_shape[:2]*crop_ratio, [img_shape[-1]]]))  # optional crop\n",
        "    image = add_gaussian_noise(image, mean=gaussian_noise_mean, stddev=gaussian_noise_stddev)\n",
        "    image = tf.image.resize(image, img_shape[:2])  # restore size\n",
        "\n",
        "    return image, label\n",
        "\n",
        "def add_gaussian_noise(image, mean=0.0, stddev=0.05):\n",
        "    noise = tf.random.normal(tf.shape(image), mean=mean, stddev=stddev)\n",
        "    image = tf.clip_by_value(image + noise, 0.0, 1.0)\n",
        "    return image\n",
        "\n",
        "class TrainingHistory(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, history):\n",
        "        super(TrainingHistory, self).__init__()\n",
        "        self.history = history  # Dictionary to store metrics\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Log training and validation metrics for each epoch\n",
        "        for metric, value in logs.items():\n",
        "            self.history.setdefault(metric, []).append(value)\n",
        "\n",
        "class JellyfishClassifier:\n",
        "    def __init__(self, num_classes, model_type='efficientnet', input_shape=(224, 224, 3),\n",
        "                 pretrained=True, metrics=None, learning_rate=0.0001):\n",
        "        '''\n",
        "        해파리 컬러 이미지를 분류하는 TensorFlow 기반 분류기\n",
        "\n",
        "        Args:\n",
        "            num_classes (int): 출력 클래스 개수\n",
        "            model_type (str): 모델 타입 ('efficientnet', 'mobilenet', 'resnet')\n",
        "            input_shape (tuple): 입력 이미지 형태 (높이, 너비, 채널)\n",
        "            pretrained (bool): 사전 학습된 가중치 사용 여부\n",
        "            metrics (list): 모델 평가 시 사용할 지표 리스트\n",
        "            learning_rate (float): 학습률\n",
        "        '''\n",
        "        # 매개변수 검증 및 저장\n",
        "        if not isinstance(num_classes, int) or num_classes <= 0:\n",
        "            raise ValueError(f\"num_classes must be positive, got {num_classes}\")\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.input_shape = input_shape\n",
        "        self.pretrained = pretrained\n",
        "        self.model_type = model_type\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # 메트릭 설정\n",
        "        self.metrics = metrics if metrics is not None else ['accuracy']\n",
        "        self._validate_metrics()\n",
        "\n",
        "        # 모델 구축\n",
        "        self.model = self._build_model()\n",
        "\n",
        "        # 학습 이력 저장소\n",
        "        self.history = {}\n",
        "        self.validation_metrics = {}\n",
        "        self.kfold_results = {}\n",
        "\n",
        "    def _validate_metrics(self):\n",
        "        '''메트릭 유효성 검사'''\n",
        "        valid_metrics = ['accuracy', 'f1_score', 'entropy']\n",
        "        for metric in self.metrics:\n",
        "            if metric not in valid_metrics:\n",
        "                raise ValueError(f\"Unsupported metric: {metric}. Supported: {valid_metrics}\")\n",
        "\n",
        "\n",
        "    def _build_model(self):\n",
        "        '''모델 구축'''\n",
        "        # 모델 타입에 따른 기본 모델 생성\n",
        "        weights = 'imagenet' if self.pretrained else None\n",
        "\n",
        "        # ----- Device Selection -----\n",
        "        if tf.test.is_gpu_available():\n",
        "            device = '/GPU:0'  # Use the first available GPU\n",
        "        else:\n",
        "            device = '/CPU:0'\n",
        "\n",
        "        with tf.device(device): # Use the selected device\n",
        "\n",
        "            if self.model_type == 'efficientnet':\n",
        "                base_model = applications.EfficientNetB0(weights=weights, include_top=False,\n",
        "                                                        input_shape=self.input_shape)\n",
        "\n",
        "                base_model.trainable = self.pretrained == False # self.pretrained 가 False 이면 trainable 은 True\n",
        "                x = base_model.output # Assign x here for efficientnet\n",
        "\n",
        "            elif self.model_type == 'VGG16':\n",
        "                base_model = applications.VGG16(\n",
        "                    weights=weights,\n",
        "                    include_top=False,\n",
        "                    input_shape=self.input_shape\n",
        "                )\n",
        "                base_model.trainable = self.pretrained == False\n",
        "                # Add normalization layer after base model\n",
        "                x = base_model.output\n",
        "\n",
        "            elif self.model_type == 'mobilenet':\n",
        "                base_model = applications.MobileNetV2(weights=weights, include_top=False,\n",
        "                                                    input_shape=self.input_shape)\n",
        "                # Add normalization layer after base model\n",
        "                x = base_model.output\n",
        "\n",
        "\n",
        "            elif self.model_type == 'resnet':\n",
        "                base_model = applications.ResNet50(weights=weights, include_top=False,\n",
        "                                                input_shape=self.input_shape)\n",
        "                # Add normalization layer after base model\n",
        "                x = base_model.output\n",
        "\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
        "\n",
        "            # 분류 헤드 추가 (decision head)\n",
        "            x = layers.Dropout(0.2)(x)\n",
        "            x = layers.GlobalAveragePooling2D()(x)  # Global Average Pooling: 특징 맵의 공간적 차원 축소\n",
        "            x = layers.Dense(256, activation='relu')(x)  # Dense Layer: 비선형 변환 및 특징 학습, ReLU 활성화 함수 사용\n",
        "            x = layers.BatchNormalization()(x) # Batch Normalization: 학습 안정화 및 속도 향상\n",
        "            x = layers.Dropout(0.1)(x)  # Dropout: 과적합 방지 (비율 조정 가능)\n",
        "            outputs = layers.Dense(self.num_classes, activation='softmax')(x)  # 최종 분류 레이어: 6가지 해파리 분류, Softmax 활성화 함수 사용\n",
        "\n",
        "            # 모델 생성\n",
        "            model = models.Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "            # 컴파일\n",
        "            optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate) # Adam optimizer 객체 생성\n",
        "\n",
        "            model.compile(\n",
        "                optimizer=optimizer, # optimizer 객체를 전달\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy']\n",
        "            )\n",
        "\n",
        "            return model\n",
        "\n",
        "    def _vgg16_preprocess_image(self, image, label=None):\n",
        "        image = image * 255.0  # Convert from [0,1] float to [0,255] float\n",
        "        image = preprocess_input(image)  # Now apply VGG preprocessing\n",
        "        return image, label\n",
        "\n",
        "    def fit(self, train_data, validation_data=None, epochs=10, batch_size=32,\n",
        "           callbacks_list=None, class_weights=None, early_stopping=0):\n",
        "        '''\n",
        "        모델 훈련\n",
        "\n",
        "        Args:\n",
        "            train_data: (X_train, y_train) 튜플 또는 제너레이터\n",
        "            validation_data: (X_val, y_val) 튜플 또는 제너레이터\n",
        "            epochs (int): 훈련 에포크 수\n",
        "            batch_size (int): 배치 크기\n",
        "            callbacks_list (list): 콜백 함수 리스트\n",
        "            class_weights (dict): 클래스 가중치\n",
        "\n",
        "        Returns:\n",
        "            self: 훈련된 분류기 객체\n",
        "        '''\n",
        "        if callbacks_list is None:\n",
        "            callbacks_list = []\n",
        "\n",
        "        # 훈련 히스토리 저장 콜백\n",
        "        history_callback = TrainingHistory(self.history)\n",
        "        callbacks_list.append(history_callback)\n",
        "\n",
        "        # 조기 종료 추가\n",
        "\n",
        "        if early_stopping > 0:\n",
        "            early_stopping_cb = callbacks.EarlyStopping(\n",
        "                monitor='val_loss', patience=early_stopping, restore_best_weights=True\n",
        "            )\n",
        "            callbacks_list.append(early_stopping_cb)\n",
        "\n",
        "\n",
        "        # 50 에포크마다 모델 저장\n",
        "        checkpoint_epochs = callbacks.ModelCheckpoint(\n",
        "            filepath='/content/drive/MyDrive/ColabNotebooks/ToyDatasets/Models/model{epoch:02d}.keras',  # 저장될 파일 경로\n",
        "            monitor='val_loss',  # 모니터링할 지표\n",
        "            save_best_only=True,  # 최상의 모델만 저장할지 여부\n",
        "            save_freq=30, # 저장 간격 (에포크)\n",
        "            verbose=1  # 진행 상황 출력 여부\n",
        "        )\n",
        "        callbacks_list.append(checkpoint_epochs)\n",
        "\n",
        "\n",
        "        # tqdm 콜백 추가 및 backend 변경\n",
        "        # tqdm.tqdm.pandas()\n",
        "        tqdm.pandas(desc=\"Processing...\")  # Set pandas backend to tqdm\n",
        "        callbacks_list.append(TqdmCallback(verbose=1))\n",
        "\n",
        "        # lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        #     monitor='val_loss', # We monitor the validation loss to decide when to reduce the learning rate.\n",
        "        #     factor=0.5,         #  When the validation loss plateaus, the learning rate is multiplied by this factor (reduced by half in this case).\n",
        "        #     patience=10,\n",
        "        #     verbose=1,\n",
        "        #     min_lr=1e-6\n",
        "        # )\n",
        "        # callbacks_list.append(lr_scheduler)\n",
        "\n",
        "        # 모델 훈련\n",
        "        if self.model_type == 'VGG16':\n",
        "            train_data = train_data.map(self._vgg16_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "            validation_data = validation_data.map(self._vgg16_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE) if validation_data else None\n",
        "\n",
        "        self.model.fit(\n",
        "            train_data.shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE),\n",
        "            validation_data=validation_data.batch(batch_size).prefetch(tf.data.AUTOTUNE) if validation_data else None,\n",
        "            callbacks=callbacks_list, # tqdm 콜백 포함\n",
        "            class_weight=class_weights,\n",
        "            epochs=epochs\n",
        "        )\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X, batch_size=32, tta=None, n_augmentations=10, hard_voting = False, verbose = 1):\n",
        "        '''\n",
        "        예측 수행 (TTA 옵션 포함)\n",
        "\n",
        "        Args:\n",
        "            X: 입력 이미지 데이터\n",
        "            batch_size (int): 배치 크기\n",
        "            n_augmentations (int): TTA가 증강한 이미지 샘플 수 (tta = tta_aug 인 경우)\n",
        "            hard_voting (bool): 하드 보팅 사용 여부 (False 인 경우 소프트 보팅)\n",
        "            verbose (int): 진행 상황 출력 여부\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: 예측 클래스\n",
        "        '''\n",
        "        if tta is not None:\n",
        "            # TTA 적용\n",
        "            preds = []\n",
        "            for x in tqdm(X, total = len(X), desc = 'Predicting with TTA', disable = verbose < 1):\n",
        "                tta_data = tf.data.Dataset.from_tensor_slices(([x])).map(tta_aug,\n",
        "                                                                         num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "                if self.model_type == 'VGG16':\n",
        "                    tta_data = tta_data.map(self._vgg16_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "                tta_imgs = [img[0].numpy() for img in tta_data.repeat().take(n_augmentations)]\n",
        "                if hard_voting:\n",
        "                    preds.append(mode(np.argmax(self.model.predict(np.array(tta_imgs)), axis = 1))[0])\n",
        "                else:\n",
        "                    # Use soft voting\n",
        "                    preds.append(np.argmax(np.mean(self.model.predict(np.array(tta_imgs)), axis = 0)))\n",
        "            return np.array(preds)\n",
        "        else:\n",
        "            # 기본 예측\n",
        "            y_pred_proba = self.model.predict(self._vgg16_preprocess_image(X)[0] if self.model_type == 'VGG16' else X)\n",
        "            return np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "    def plot_confusion_matrix(self, class_names=None):\n",
        "        '''\n",
        "        혼동 행렬 시각화\n",
        "\n",
        "        Args:\n",
        "            class_names (list): 클래스 이름 리스트\n",
        "        '''\n",
        "        if 'confusion_matrix' not in self.validation_metrics:\n",
        "            print(\"No confusion matrix available. Run evaluate() first.\")\n",
        "            return\n",
        "\n",
        "        cm = self.validation_metrics['confusion_matrix']\n",
        "\n",
        "        if class_names is None:\n",
        "            class_names = [f'Class {i}' for i in range(self.num_classes)]\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=class_names, yticklabels=class_names)\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.show()\n",
        "\n",
        "    def save_model(self, filepath):\n",
        "        '''모델 저장'''\n",
        "        self.model.save(filepath)\n",
        "        print(f\"Model saved to {filepath}\")\n",
        "\n",
        "    def load_model(self, filepath):\n",
        "        '''모델 불러오기'''\n",
        "        self.model = tf.keras.models.load_model(filepath)\n",
        "        print(f\"Model loaded from {filepath}\")\n",
        "\n",
        "\n",
        "def count_images_per_class(folder_path):\n",
        "    \"\"\"\n",
        "    특정 폴더 내의 클래스별 이미지 개수를 셉니다.\n",
        "\n",
        "    Args:\n",
        "        folder_path: 이미지가 있는 폴더 경로\n",
        "\n",
        "    Returns:\n",
        "        클래스별 이미지 개수를 담은 딕셔너리\n",
        "    \"\"\"\n",
        "    class_counts = {}\n",
        "    for class_name in os.listdir(folder_path):\n",
        "        class_folder = os.path.join(folder_path, class_name)\n",
        "        if os.path.isdir(class_folder):\n",
        "            class_counts[class_name] = len(os.listdir(class_folder))\n",
        "    return class_counts\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):  # pred_index : 관심 클래스의 인덱스\n",
        "    # Grad-CAM 모델 생성\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Gradient 계산\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # Gradient의 평균 계산, 모델이 어느 클래스 방향으로 더 당겼는지?\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Heatmap 생성\n",
        "    heatmap = last_conv_layer_output[0] @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_gradcam(img_path, heatmap, alpha=0.4):\n",
        "    # 이미지 로드 및 크기 조정\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "\n",
        "    # Heatmap 크기 조정 및 색상 적용\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
        "\n",
        "    # Heatmap과 원본 이미지 합치기\n",
        "    superimposed_img = heatmap * alpha + img\n",
        "    superimposed_img = np.clip(superimposed_img, 0, 255).astype(np.uint8)  # 픽셀 값 범위 조정\n",
        "\n",
        "    # 결과 출력\n",
        "    plt.figure(figsize=(8, 8))  # 이미지 크기 조정 (필요에 따라 변경)\n",
        "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Grad-CAM Visualization\")  # 제목 설정 (필요에 따라 변경)\n",
        "    plt.axis('off')  # 축 제거\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqA8Vuvf_Tqw",
        "outputId": "7959e484-41ac-4ba5-bfb7-2dcf3801f895"
      },
      "outputs": [],
      "source": [
        "# 원본 데이터셋의 경로 설정\n",
        "data_path = \"/content/drive/MyDrive/ColabNotebooks/ToyDatasets/jellyfish-dataset/Train_Test_Valid\"\n",
        "train_path = \"/content/drive/MyDrive/ColabNotebooks/ToyDatasets/jellyfish-dataset/Train_Test_Valid/Train\"\n",
        "val_path = \"/content/drive/MyDrive/ColabNotebooks/ToyDatasets/jellyfish-dataset/Train_Test_Valid/valid\"\n",
        "test_path = \"/content/drive/MyDrive/ColabNotebooks/ToyDatasets/jellyfish-dataset/Train_Test_Valid/test\"\n",
        "\n",
        "# 클린 데이터셋의 경로 설정\n",
        "clean_data_path = \"/content/drive/MyDrive/ColabNotebooks/ToyDatasets/jellyfish-dataset/Clean_dataset\"\n",
        "clean_train_path = \"/content/drive/MyDrive/ColabNotebooks/ToyDatasets/jellyfish-dataset/Clean_dataset/Train\"\n",
        "clean_val_path = \"/content/drive/MyDrive/ColabNotebooks/ToyDatasets/jellyfish-dataset/Clean_dataset/valid\"\n",
        "clean_test_path = \"/content/drive/MyDrive/ColabNotebooks/ToyDatasets/jellyfish-dataset/Clean_dataset/test\"\n",
        "\n",
        "print(f\"원본 데이터셋 경로:\")\n",
        "print(train_path)\n",
        "print(val_path)\n",
        "print(test_path)\n",
        "print()\n",
        "print(f\"클린 데이터셋 경로:\")\n",
        "print(clean_train_path)\n",
        "print(clean_val_path)\n",
        "print(clean_test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqw3Ga98rYwe",
        "outputId": "eb1399a0-18d3-4835-a156-58ec70aa6284"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk6DQMagTKoE"
      },
      "source": [
        "### 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nlWiDUZHhfH",
        "outputId": "6eabb630-41cc-446b-bd38-8305e5e54fe0"
      },
      "outputs": [],
      "source": [
        "img_size = (224, 224)  # 일반적인 CNN 입력 크기\n",
        "# 데이터 로드\n",
        "X_train, y_train, class_dict = load_dataset_from_directory(clean_train_path, img_size=img_size)\n",
        "X_test, y_test, _ = load_dataset_from_directory(clean_test_path, img_size=img_size)\n",
        "X_valid, y_valid, _ = load_dataset_from_directory(clean_val_path, img_size=img_size)\n",
        "\n",
        "# 데이터 정보 출력\n",
        "print(f\"클래스 정보: {class_dict}\")\n",
        "print(f\"훈련 데이터: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"테스트 데이터: {X_test.shape}, {y_test.shape}\")\n",
        "print(f\"검증 데이터: {X_valid.shape}, {y_valid.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kZISn6o7LuJ",
        "outputId": "9690d28d-c01b-4c0f-a626-ad7ab5f6f52a"
      },
      "outputs": [],
      "source": [
        "# train_path와 val_path에서 클래스별 이미지 개수 세기\n",
        "train_counts = count_images_per_class(clean_train_path)\n",
        "val_counts = count_images_per_class(clean_val_path)\n",
        "test_counts = count_images_per_class(clean_test_path)\n",
        "# 데이터프레임 생성\n",
        "df = pd.DataFrame({'train': train_counts, 'val': val_counts, 'test': test_counts})\n",
        "\n",
        "# NaN 값을 0으로 채우기\n",
        "df = df.fillna(0).astype(int)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"원본 이미지 개수:\\n{df}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "slqCUSyOm2T2",
        "outputId": "d4500b79-a1a9-4a86-be48-dbf640f8cef6"
      },
      "outputs": [],
      "source": [
        "# 원본 이미지 확인\n",
        "# 9개의 랜덤 이미지 추출\n",
        "random_indices = np.random.choice(X_train.shape[0], size=9, replace=False)\n",
        "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "  ax.imshow(X_train[random_indices[i]])\n",
        "  ax.set_title(list(class_dict.keys())[y_train[random_indices[i]]])\n",
        "  ax.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OnFBTHkTC9i"
      },
      "source": [
        "### 훈련 데이터 증강"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv0s_uqzgWwY"
      },
      "outputs": [],
      "source": [
        "# Construct the tf.data pipeline\n",
        "train_dataset_no_aug = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "valid_dataset_no_aug = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
        "\n",
        "# Construct the tf.data pipeline\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).map(lambda img, label: augment(img, label,\n",
        "            crop_ratio=0.9,\n",
        "            saturation = (0.4, 1.0),\n",
        "            brightness_max_delta=0.2,\n",
        "            random_contrast=(0.95,1.00),\n",
        "            random_hue = 0.2,\n",
        "            random_flip_left_right = True,\n",
        "            random_flip_up_down = True,\n",
        "            random_rotation = 360, #TODO: There is only 90 degree flip\n",
        "            gaussian_noise_mean=0.05,\n",
        "            gaussian_noise_stddev=0.1\n",
        "            ),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid, y_valid)).map(lambda img, label: augment(img, label,\n",
        "            crop_ratio=0.9,\n",
        "            # saturation = (0.4, 1.0),\n",
        "            # brightness_max_delta=0.2,\n",
        "            random_contrast=(0.9,1.0),\n",
        "            # random_hue = 0.2,\n",
        "            random_flip_left_right = True,\n",
        "            random_flip_up_down = True,\n",
        "            random_rotation = 360,\n",
        "            gaussian_noise_mean=0.02,\n",
        "            gaussian_noise_stddev=0.02\n",
        "            ), num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "z1X3rYJX7Lj1",
        "outputId": "734bac5d-25d5-4e1b-868d-90b6a58454e2"
      },
      "outputs": [],
      "source": [
        "aug_imgs = [img for img in valid_dataset.shuffle(1000).take(9)]\n",
        "# 훈련용 증강 이미지 확인 (datagen x)\n",
        "# 9개의 랜덤 이미지 추출\n",
        "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "  ax.imshow(aug_imgs[i][0].numpy().clip(0,1))\n",
        "  ax.set_title(list(class_dict.keys())[aug_imgs[i][1]])\n",
        "  ax.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23P8LgrlSgxt"
      },
      "source": [
        "### 모델 정의 및 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "PqOlMWJA57NF",
        "outputId": "902ebf0b-6428-4ba1-cbdc-215dc36fd01c"
      },
      "outputs": [],
      "source": [
        "# [EfficientNetB0/VGG16] 분류기 초기화\n",
        "classifier = JellyfishClassifier(\n",
        "    num_classes=6,  # 해파리 클래스 수\n",
        "    #model_type='efficientnet',\n",
        "    model_type='VGG16',\n",
        "    pretrained=True,  # ImageNet 가중치 사용\n",
        "    metrics=['accuracy', 'f1_score'],  # 평가 지표에서 entropy 제거 -> evaluate 에서 계산\n",
        "    learning_rate=1e-4  # 학습률 조정\n",
        ")\n",
        "# 2. 분류기 인스턴스에서 모델 서머리 출력:\n",
        "classifier.model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "vVJuP2YLYXv0",
        "outputId": "edb7bbcc-1a7d-4591-aebd-7eccb2c24180"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(classifier.model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2c2a38b33b684aa496bc05f296075807",
            "14eb0aae47ef4ad980a10dc08d1025e9",
            "6e984459f4c247348982184e6e37b39b",
            "d60a265f2e6b40e1a51fa86083dcb4a8",
            "07425bf1baca4a81a8aeb89db2bd794e",
            "8dc637f1a2214abd9d022737007dfd8c",
            "de28bc62050b44b29438d04f95e0aa90",
            "e8b9562ce49d4956b98cfd8ca6b7cb96",
            "b507f8c985ab464495f71355192e2ea2",
            "b0909655944b4bbe9585faa6b3caf0df",
            "1c56363baa524d4a833422a1c1dd60b1",
            "3cf1ac1b2f0a49f8b59c5d8db48c325a",
            "033bb3b26ed04503ac20244e998b1d8d",
            "b2926e4cab634618ac4e413237f157cd",
            "48e97ba0ca0b42528e6556d6168422af",
            "3354dd61ea234c73a98f5ae5756cfb56",
            "e531e27b56ad4b7a84753a089cec0838",
            "8b24057c33354bd9a049f39a592515b1",
            "42bfbcb927ac4a17b2f1636942dda356",
            "7ec907b65f2742258f3e78abee17f3c0",
            "ca48a2c9b1a24422a731e47cafd22e16",
            "948b9951ce624fbfba410ac2e16d38b5"
          ]
        },
        "collapsed": true,
        "id": "N8lBHEdh8U7o",
        "outputId": "d0bfc9fc-f1bd-4d16-a74d-af8e07a9e748"
      },
      "outputs": [],
      "source": [
        "# 모델 훈련\n",
        "# JellyfishClassifier 클래스 내부의 fit 메서드에서 TTA 자동 적용\n",
        "classifier.fit(\n",
        "    #train_dataset, valid_dataset_no_aug,  # train_dataset: 이터레이터를 통해 증강된 이미지들\n",
        "    #train_dataset_no_aug, valid_dataset_no_aug,\n",
        "    train_dataset, valid_dataset,\n",
        "    epochs=500,\n",
        "    early_stopping=-1,\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "lsLm9oyqPvhV",
        "outputId": "209963c0-7a44-4968-a68b-c7af913f2cbb"
      },
      "outputs": [],
      "source": [
        "# 훈련 검증 시각화\n",
        "# classifier 객체가 검증 지표를 담은 history 를 가지고 있음\n",
        "history = classifier.history\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (8, 6), nrows = 2)\n",
        "ax[0].set(title='Training and Validation Accuracy', xlabel='Epoch', ylabel='Accuracy')\n",
        "ax[0].grid()\n",
        "ax[0].plot(history['accuracy'], label='Train Accuracy')\n",
        "ax[0].plot(history['val_accuracy'], label='Validation Accuracy')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].set(title='Training and Validation Loss Values', xlabel='Epoch', ylabel='Loss')\n",
        "ax[1].grid()\n",
        "ax[1].plot(history['loss'], label='Train Loss')\n",
        "ax[1].plot(history['val_loss'], label='Validation Loss')\n",
        "ax[1].legend()\n",
        "\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VWyeNjzzUpU",
        "outputId": "5b5d723b-67e5-45d7-ce49-8993f804e8bd"
      },
      "outputs": [],
      "source": [
        "classifier.model.evaluate(X_train, y_train), classifier.model.evaluate(X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Icupx-7WaoEd"
      },
      "outputs": [],
      "source": [
        "#classifier.predict(X_train)\n",
        "#print(np.argmax(classifier.model.predict(X_valid), axis = 1))\n",
        "#print(classifier.model.predict(X_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7T28XZZS0AM"
      },
      "source": [
        "### 추론 및 검증"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orqmV7-vUOs2",
        "outputId": "01febaf4-1bb4-4fe6-9e27-9fd99f30c64f"
      },
      "outputs": [],
      "source": [
        "# Test-Time-Augmentation (TTA)\n",
        "'''\n",
        "테스트 시간에 어떤 증강을 넣을 지 설정할 수 있다.\n",
        "tta = None: 테스트 데이터를 증강하지 않는다.\n",
        "hard_voting: hard_voting=True\n",
        "soft_voting: hard_voting=False\n",
        "n_augmentation: 테스트 샘플 당 증강 이미지 개수\n",
        "'''\n",
        "tta_aug = lambda img: augment(img, label = None,\n",
        "            crop_ratio=0.9,\n",
        "            saturation = (0.4, 1.0),\n",
        "            brightness_max_delta=0.5,\n",
        "            random_contrast=(0.9,1.1),\n",
        "            random_hue = 0.1)\n",
        "\n",
        "pred = classifier.predict(X_valid, tta = None)\n",
        "pred_tta_soft_voting = classifier.predict(X_valid, tta = tta_aug, hard_voting = False, n_augmentations = 10)\n",
        "pred_tta_hard_voting = classifier.predict(X_valid, tta = tta_aug, hard_voting = True, n_augmentations = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QUbuHcA-nkQH",
        "outputId": "e7a0c6c1-dfca-4ef4-939e-c80b16244170"
      },
      "outputs": [],
      "source": [
        "classes = {v: k for k, v in class_dict.items()}\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 14), nrows = 3)\n",
        "sns.heatmap(confusion_matrix(y_valid, pred), ax = ax[0], annot=True, fmt='d', cmap='Blues', xticklabels=[classes[c] for c in sorted(classes.keys())], yticklabels=[classes[c] for c in sorted(classes.keys())])\n",
        "sns.heatmap(confusion_matrix(y_valid, pred_tta_soft_voting), ax = ax[1], annot=True, fmt='d', cmap='Blues', xticklabels=[classes[c] for c in sorted(classes.keys())], yticklabels=[classes[c] for c in sorted(classes.keys())])\n",
        "sns.heatmap(confusion_matrix(y_valid, pred_tta_hard_voting), ax = ax[2], annot=True, fmt='d', cmap='Blues', xticklabels=[classes[c] for c in sorted(classes.keys())], yticklabels=[classes[c] for c in sorted(classes.keys())])\n",
        "\n",
        "ax[0].set_title('Confusion Matrix (no TTA)')\n",
        "ax[1].set_title('Confusion Matrix (TTA soft voting)')\n",
        "ax[2].set_title('Confusion Matrix (TTA hard voting)')\n",
        "\n",
        "for axis in ax:\n",
        "    axis.set_xlabel('Predicted Labels')\n",
        "    axis.set_ylabel('True Labels')\n",
        "fig.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YitkAaTI4NQ8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imer21Mq93rD"
      },
      "outputs": [],
      "source": [
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):  # pred_index : 관심 클래스의 인덱스\n",
        "    # Grad-CAM 모델 생성\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Gradient 계산\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # Gradient의 평균 계산, 모델이 어느 클래스 방향으로 더 당겼는지?\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Heatmap 생성\n",
        "    heatmap = last_conv_layer_output[0] @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_gradcam(img_path, heatmap, alpha=0.4):\n",
        "    # 이미지 로드 및 크기 조정\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "\n",
        "    # Heatmap 크기 조정 및 색상 적용\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
        "\n",
        "    # Heatmap과 원본 이미지 합치기\n",
        "    superimposed_img = heatmap * alpha + img\n",
        "    superimposed_img = np.clip(superimposed_img, 0, 255).astype(np.uint8)  # 픽셀 값 범위 조정\n",
        "\n",
        "    # 결과 출력\n",
        "    plt.figure(figsize=(8, 8))  # 이미지 크기 조정 (필요에 따라 변경)\n",
        "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Grad-CAM Visualization\")  # 제목 설정 (필요에 따라 변경)\n",
        "    plt.axis('off')  # 축 제거\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDLX4FxyoXJr"
      },
      "outputs": [],
      "source": [
        "last_conv_layer_name = \"block5_conv3\"  # VGG16의 경우\n",
        "gradcam_imgs = []\n",
        "gradcam_heatmaps = []\n",
        "for gaussian_noise_mean in np.hstack([np.linspace(0, 1, 10), np.linspace(0, 1, 10)[::-1]]):\n",
        "    gradcam_dataset = tf.data.Dataset.from_tensor_slices((X_train[:1], y_train[:1])).map(lambda img, label: augment(img, label,\n",
        "        crop_ratio=0.0,\n",
        "        saturation = (0.0, 0.0),\n",
        "        brightness_max_delta=0.0,\n",
        "        random_contrast=(0.0,0.0),\n",
        "        random_hue = 0.0,\n",
        "        random_flip_left_right = False,\n",
        "        random_flip_up_down = False,\n",
        "        random_rotation = 0,\n",
        "        gaussian_noise_mean=gaussian_noise_mean,\n",
        "        gaussian_noise_stddev=0.1\n",
        "        ),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    gradcam_imgs.append(gradcam_dataset.shuffle(1).take(1))\n",
        "    gradcam_heatmaps.append(make_gradcam_heatmap(gradcam_imgs[-1], classifier.model, last_conv_layer_name))\n",
        "gradcam_imgs = np.array(gradcam_imgs)\n",
        "gradcam_heatmaps = np.array(gradcam_heatmaps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-7jmOnKoG0m"
      },
      "outputs": [],
      "source": [
        "last_conv_layer_name = \"block5_conv3\"  # VGG16의 경우\n",
        "\n",
        "# Grad-CAM 히트맵 생성 및 시각화\n",
        "heatmap = make_gradcam_heatmap(gradcam_imgs, classifier.model, last_conv_layer_name)\n",
        "#display_gradcam(img_path, heatmap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBagjFLPJ1GG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRsQWwRcH3a8"
      },
      "source": [
        "### Grad-CAM 시각화\n",
        "- 빨간색: 모델이 가장 중요하다고 판단한 이미지 영역\n",
        "- 파란색: 덜 중요하다고 본 부분\n",
        "\n",
        "해피리의 촉수나 형태에 초점이 맞춰졌다면 잘 학습된 것"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "yZRyYgkSEnFk",
        "outputId": "12c065e4-c72d-4ab1-d39c-6961bfbf7c2a"
      },
      "outputs": [],
      "source": [
        "# 이미지 경로\n",
        "img_path = \"/content/drive/MyDrive/ColabNotebooks/ToyDatasets/jellyfish-dataset/ext_dataset/pelagia26_IMG_00009.jpg\"\n",
        "\n",
        "# 이미지 전처리\n",
        "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = img_array / 255.0  # 정규화\n",
        "\n",
        "# 마지막 컨볼루션 레이어 이름\n",
        "last_conv_layer_name = \"block5_conv3\"  # VGG16의 경우\n",
        "\n",
        "# Grad-CAM 히트맵 생성 및 시각화\n",
        "heatmap = make_gradcam_heatmap(img_array, classifier.model, last_conv_layer_name)\n",
        "display_gradcam(img_path, heatmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db7ChicJSTqL"
      },
      "source": [
        "### ( 더이상 사용하지는 않지만 ) 실험의 흔적"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "-a1owJwxzATI",
        "outputId": "76776098-6969-48ba-f7e5-840561189cb6"
      },
      "outputs": [],
      "source": [
        "# [테스트용] 데이터제너레이터를 사용하지 않은 TTA 증강 설정\n",
        "# 임시 시각화를 위해 훈련 이미지 사용\n",
        "tta_aug = lambda img: augment(img, label = None,\n",
        "            crop_ratio=0.9,\n",
        "            saturation = (0.4, 1.0),\n",
        "            brightness_max_delta=0.5,\n",
        "            random_contrast=(0.9,1.1),\n",
        "            random_hue = 0.1)\n",
        "\n",
        "tta_data = tf.data.Dataset.from_tensor_slices(([X_train[0]])).map(tta_aug,\n",
        "    num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "tta_imgs = [img[0].numpy() for img in tta_data.repeat().take(10)]\n",
        "\n",
        "# 9개의 랜덤 이미지 추출하여 테스트 증강 시각화\n",
        "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "  ax.imshow(tta_imgs[i].clip(0, 1))\n",
        "  ax.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "ojdCm_2WNojp",
        "outputId": "1bee7701-2148-4dca-be2d-8811d0070d38"
      },
      "outputs": [],
      "source": [
        "# # 증강 이미지 확인 (datagen x)\n",
        "# # 9개의 랜덤 이미지 추출\n",
        "# random_indices = np.random.choice(aug_imgs.shape[0], size=9, replace=False)\n",
        "# fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "# for i, ax in enumerate(axes.flat):\n",
        "#   ax.imshow(aug_imgs[random_indices[i]])\n",
        "#   ax.set_title(list(class_dict.keys())[y_train[random_indices[i]]])\n",
        "#   ax.axis('off')\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "033bb3b26ed04503ac20244e998b1d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e531e27b56ad4b7a84753a089cec0838",
            "placeholder": "​",
            "style": "IPY_MODEL_8b24057c33354bd9a049f39a592515b1",
            "value": " 67%"
          }
        },
        "07425bf1baca4a81a8aeb89db2bd794e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14eb0aae47ef4ad980a10dc08d1025e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dc637f1a2214abd9d022737007dfd8c",
            "placeholder": "​",
            "style": "IPY_MODEL_de28bc62050b44b29438d04f95e0aa90",
            "value": "100%"
          }
        },
        "1c56363baa524d4a833422a1c1dd60b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c2a38b33b684aa496bc05f296075807": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14eb0aae47ef4ad980a10dc08d1025e9",
              "IPY_MODEL_6e984459f4c247348982184e6e37b39b",
              "IPY_MODEL_d60a265f2e6b40e1a51fa86083dcb4a8"
            ],
            "layout": "IPY_MODEL_07425bf1baca4a81a8aeb89db2bd794e"
          }
        },
        "3354dd61ea234c73a98f5ae5756cfb56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "3cf1ac1b2f0a49f8b59c5d8db48c325a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_033bb3b26ed04503ac20244e998b1d8d",
              "IPY_MODEL_b2926e4cab634618ac4e413237f157cd",
              "IPY_MODEL_48e97ba0ca0b42528e6556d6168422af"
            ],
            "layout": "IPY_MODEL_3354dd61ea234c73a98f5ae5756cfb56"
          }
        },
        "42bfbcb927ac4a17b2f1636942dda356": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e97ba0ca0b42528e6556d6168422af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca48a2c9b1a24422a731e47cafd22e16",
            "placeholder": "​",
            "style": "IPY_MODEL_948b9951ce624fbfba410ac2e16d38b5",
            "value": " 10.0/15.0 [00:00&lt;00:00, 17.5batch/s, accuracy=0.984, loss=0.0399]"
          }
        },
        "6e984459f4c247348982184e6e37b39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8b9562ce49d4956b98cfd8ca6b7cb96",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b507f8c985ab464495f71355192e2ea2",
            "value": 500
          }
        },
        "7ec907b65f2742258f3e78abee17f3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b24057c33354bd9a049f39a592515b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dc637f1a2214abd9d022737007dfd8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "948b9951ce624fbfba410ac2e16d38b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0909655944b4bbe9585faa6b3caf0df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2926e4cab634618ac4e413237f157cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42bfbcb927ac4a17b2f1636942dda356",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ec907b65f2742258f3e78abee17f3c0",
            "value": 15
          }
        },
        "b507f8c985ab464495f71355192e2ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca48a2c9b1a24422a731e47cafd22e16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d60a265f2e6b40e1a51fa86083dcb4a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0909655944b4bbe9585faa6b3caf0df",
            "placeholder": "​",
            "style": "IPY_MODEL_1c56363baa524d4a833422a1c1dd60b1",
            "value": " 500/500 [08:48&lt;00:00,  1.05s/epoch, accuracy=0.985, loss=0.0456, val_accuracy=0.788, val_loss=0.727]"
          }
        },
        "de28bc62050b44b29438d04f95e0aa90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e531e27b56ad4b7a84753a089cec0838": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b9562ce49d4956b98cfd8ca6b7cb96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
