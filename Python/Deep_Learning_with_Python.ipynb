{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSjXjxgQ7GyGNnnkkw/P2N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophie-myk/AIFFEL_quest_cr/blob/main/Python/Deep_Learning_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "IQkrM3U8N9Pg"
      },
      "outputs": [],
      "source": [
        "#입력데이터\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 *28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28*28))\n",
        "test_images = test_images.astype(\"float32\") /255"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model = keras.Sequential([\n",
        "     layers.Dense( 512, activation= \"relu\"),\n",
        "     layers.Dense(10, activation= \"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "O0AhP2ZZxN3B"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델을 컴파일하는 단계\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\", #손실함수\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "HOzk5Lwgxj7r"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#마지막으로, 훈련반복\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CprEPIyfxrr5",
        "outputId": "be9f4ee6-a600-4c85-93dd-1fa7647c82bb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8721 - loss: 0.4438\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9652 - loss: 0.1176\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9778 - loss: 0.0726\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9843 - loss: 0.0507\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9896 - loss: 0.0363\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e65a7d84e10>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 첫번째 예제를 다시 밑바닥부터 구현\n",
        "import tensorflow as tf\n",
        "\n",
        "class NaiveDense:\n",
        "    def __init__(self, input_size, output_size, activation):\n",
        "        self.activation = activation\n",
        "\n",
        "        # Initialize weights\n",
        "        w_shape = (input_size, output_size)\n",
        "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
        "        self.W = tf.Variable(w_initial_value)\n",
        "\n",
        "        # Initialize biases\n",
        "        b_shape = (output_size,)\n",
        "        b_initial_value = tf.zeros(b_shape)\n",
        "        self.b = tf.Variable(b_initial_value)\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        return [self.W, self.b]"
      ],
      "metadata": {
        "id": "02crPrnYya_o"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "class NaiveSequential:\n",
        "  def __init__(self,layers):\n",
        "      self.layers = layers\n",
        "\n",
        "  def __call__(self,inputs):\n",
        "      x = inputs\n",
        "      for layer in self.layers:\n",
        "        x = layer(x)\n",
        "      return x\n",
        "\n",
        "  @property\n",
        "  def weights(self):\n",
        "    weights = []\n",
        "    for layer in self.layers:\n",
        "        weights += layer.weights\n",
        "    return weights"
      ],
      "metadata": {
        "id": "TAEXb2NB1IFf"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NaiveSequential([\n",
        "    NaiveDense(input_size= 28*28, output_size=512, activation=tf.nn.relu),\n",
        "    NaiveDense(input_size= 512, output_size=10, activation=tf.nn.softmax)\n",
        "])\n",
        "assert len(model.weights) == 4"
      ],
      "metadata": {
        "id": "gYrJikIr2U5U"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#배치 제너레이터\n",
        "import math\n",
        "\n",
        "class BatchGenerator:\n",
        "  def __init__(self, images, labels, batch_size:128):\n",
        "      assert len(images) == len(labels)\n",
        "      self.index = 0\n",
        "      self.images = images\n",
        "      self.labels = labels\n",
        "      self.batch_size = batch_size\n",
        "      self.num_batches = math.ceil(len(images)/batch_size)\n",
        "\n",
        "  def next(self):\n",
        "    images = self.images[self.index : self.index + self.batch_size]\n",
        "    labels = self.labels[self.index : self.index + self.batch_size]\n",
        "    self.index += self.batch_size\n",
        "    return images,labels"
      ],
      "metadata": {
        "id": "UHp1ChST4Ncn"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련스텝 실행하기\n",
        "\n",
        "def one_training_step(model, images_batch, labels_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = model(images_batch)\n",
        "      per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(labels_batch, predictions)\n",
        "      average_loss = tf.reduce_mean(per_sample_losses)\n",
        "    gradients = tape.gradient(average_loss, model.weights)\n",
        "    update_weights(gradients, model.weights)\n",
        "    return average_loss"
      ],
      "metadata": {
        "id": "fzZOb3Rd6hHt"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "  for g, w in zip(gradients, weights):\n",
        "    w.assign_sub(g * learning_rate)"
      ],
      "metadata": {
        "id": "QN38_o0s7suB"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import optimizers\n",
        "\n",
        "# Change the name to 'optimizer' to avoid confusion\n",
        "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    # Now you can use 'optimizer' here\n",
        "    optimizer.apply_gradients(zip(gradients, weights))"
      ],
      "metadata": {
        "id": "yH1OD16j8DDg"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#전체 훈련 루프_단순한 에포크의 반복전체 훈련 루프_단순한 에포크의 반복\n",
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "    for epoch_counter in range(epochs):\n",
        "        print(f\"에포크 {epoch_counter}\")\n",
        "        batch_generator = BatchGenerator(images, labels, batch_size)\n",
        "        for batch_counter in range(batch_generator.num_batches):\n",
        "            images_batch, labels_batch = batch_generator.next()\n",
        "            loss = one_training_step(model, images_batch, labels_batch)\n",
        "            if batch_counter % 100 == 0:\n",
        "                print(f\"{batch_counter}번째 손실: {loss:.2f}\")"
      ],
      "metadata": {
        "id": "MAfUKJUf8wzX"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 *28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28*28))\n",
        "test_images = test_images.astype(\"float32\") /255\n",
        "\n",
        "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LI7o15a-RTh",
        "outputId": "da24cde9-847c-4b5a-d5a4-6b171fb35331"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크 0\n",
            "0번째 손실: 6.13\n",
            "100번째 손실: 2.23\n",
            "200번째 손실: 2.20\n",
            "300번째 손실: 2.07\n",
            "400번째 손실: 2.20\n",
            "에포크 1\n",
            "0번째 손실: 1.85\n",
            "100번째 손실: 1.86\n",
            "200번째 손실: 1.82\n",
            "300번째 손실: 1.69\n",
            "400번째 손실: 1.80\n",
            "에포크 2\n",
            "0번째 손실: 1.53\n",
            "100번째 손실: 1.56\n",
            "200번째 손실: 1.49\n",
            "300번째 손실: 1.41\n",
            "400번째 손실: 1.48\n",
            "에포크 3\n",
            "0번째 손실: 1.28\n",
            "100번째 손실: 1.33\n",
            "200번째 손실: 1.23\n",
            "300번째 손실: 1.20\n",
            "400번째 손실: 1.24\n",
            "에포크 4\n",
            "0번째 손실: 1.09\n",
            "100번째 손실: 1.15\n",
            "200번째 손실: 1.04\n",
            "300번째 손실: 1.04\n",
            "400번째 손실: 1.08\n",
            "에포크 5\n",
            "0번째 손실: 0.95\n",
            "100번째 손실: 1.01\n",
            "200번째 손실: 0.90\n",
            "300번째 손실: 0.93\n",
            "400번째 손실: 0.97\n",
            "에포크 6\n",
            "0번째 손실: 0.85\n",
            "100번째 손실: 0.91\n",
            "200번째 손실: 0.80\n",
            "300번째 손실: 0.84\n",
            "400번째 손실: 0.88\n",
            "에포크 7\n",
            "0번째 손실: 0.77\n",
            "100번째 손실: 0.82\n",
            "200번째 손실: 0.72\n",
            "300번째 손실: 0.77\n",
            "400번째 손실: 0.82\n",
            "에포크 8\n",
            "0번째 손실: 0.71\n",
            "100번째 손실: 0.76\n",
            "200번째 손실: 0.66\n",
            "300번째 손실: 0.71\n",
            "400번째 손실: 0.77\n",
            "에포크 9\n",
            "0번째 손실: 0.67\n",
            "100번째 손실: 0.70\n",
            "200번째 손실: 0.61\n",
            "300번째 손실: 0.67\n",
            "400번째 손실: 0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 평가하기\n",
        "import numpy as np # Add this line to import numpy\n",
        "\n",
        "predictions = model(test_images)\n",
        "predictions = predictions.numpy()\n",
        "predicted_labels = np.argmax(predictions, axis=1) # Now np is defined and can be used\n",
        "matches = predicted_labels == test_labels\n",
        "print(f\"정확도: {matches.mean():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k437q8cBjee",
        "outputId": "99f9577d-18c2-4b91-b306-cb6927981765"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.81\n"
          ]
        }
      ]
    }
  ]
}